{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187869b5-b9ef-4143-ae78-a4dbe13d6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Settings\n",
    "os.environ[\"QUERY_OPENAI\"] = \"True\"  # if set to True, this generates a random result instead of prompting the LLM\n",
    "os.environ[\"OPENAI_MODEL\"] = \"gpt-5-mini\"  # the model to use on the OpenAI API\n",
    "os.environ[\"OPENAI_N\"] = \"15\"  # the number of answers to generate per prompt\n",
    "os.environ[\"OPENAI_TEMPERATURE\"] = \"1.0\"  # the model temperature to use\n",
    "os.environ[\"OPENAI_TIMEOUT\"] = \"60\"  # the timeout for OpenAI API calls\n",
    "os.environ[\"TEMPLATE_DIR\"] = \"templates/\"\n",
    "os.environ[\"SQLITE_PATH\"] = str(None) #\"gpt4_results.sqlite3\"  the path to the SQLite database file. Set this to None to disable storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee057f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af61b7c-a5f6-49d4-93a8-bf95123438d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the environment variables before loading fm_matcher, otherwise the settings above will be ignored\n",
    "from fm_matcher.utils import storage\n",
    "from fm_matcher.utils.models import Attribute, Parameters, Relation, Result, Side\n",
    "from fm_matcher.utils.prompt_building import PromptDesign, build_prompts\n",
    "from fm_matcher.utils.prompt_sending import process_prompt_list\n",
    "from fm_matcher.utils.prompt_postprocessing import postprocess_answers\n",
    "\n",
    "all_templates = [f\"{mode}\" for mode in (\"oneToN\", \"nToOne\", \"nToN\")]\n",
    "all_modes = [PromptDesign.oneToN, PromptDesign.nToOne, PromptDesign.nToN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2131a14c-9c49-4051-9afc-96de6c979763",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv(\"benchmark/ground_truth.csv\")\n",
    "for side in (\"source\", \"target\"):\n",
    "    benchmark[[f\"{side}_schema\", f\"{side}_relation\", f\"{side}_attribute\"]] = benchmark[side].str.split(\".\", expand=True)\n",
    "    benchmark[side] = benchmark[side].str.lower()\n",
    "benchmark[\"benchmark\"] = True\n",
    "\n",
    "relation_combinations = benchmark[[\"source_relation\", \"target_relation\"]].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f237dbe-c7eb-4bad-8f73-bd50549d67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def get_description(schema: str, table: str, attribute: Optional[str] = None) -> str:\n",
    "    if attribute:\n",
    "        filename = f\"{schema}_{table}_{attribute}.txt\"\n",
    "    else:\n",
    "        filename = f\"{schema}_table_{table}.txt\"\n",
    "    filename_filter = lambda f: f.lower() == filename.lower()\n",
    "    filename = next(filter(filename_filter, os.listdir(\"schema_documentations\")))\n",
    "    with open(os.path.join(\"schema_documentations\", filename), \"r\") as desc_file:\n",
    "        description = desc_file.read()\n",
    "    return description\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_attributes(schema: str, table: str) -> List[str]:\n",
    "    table_filter = lambda f: f.lower().startswith(f\"{schema}_{table}_\") and f.endswith(\".txt\")\n",
    "    extract_attr_name = lambda f: f[len(f\"{schema}_{table}_\"):-len(\".txt\")]\n",
    "    return [\n",
    "        extract_attr_name(attr_file)\n",
    "        for attr_file in filter(table_filter, os.listdir(\"schema_documentations/\"))\n",
    "    ]\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_relation(schema: str, table: str) -> Relation:\n",
    "    schema, table = schema.lower(), table.lower()\n",
    "    description = get_description(schema, table)\n",
    "    attributes = [\n",
    "        Attribute(\n",
    "            name=attr_name.capitalize(),\n",
    "            description=get_description(schema, table, attr_name),\n",
    "        ) for attr_name in get_attributes(schema, table)\n",
    "    ]\n",
    "    side = Side.SOURCE if schema == \"mimic\" else Side.TARGET\n",
    "    return Relation(\n",
    "        name=table.capitalize(),\n",
    "        side=side,\n",
    "        description=description,\n",
    "        attributes=attributes,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    Parameters(\n",
    "        source_relation=get_relation(\"mimic\", source),\n",
    "        target_relation=get_relation(\"omop\", target),\n",
    "    ) for source, target in relation_combinations\n",
    "]\n",
    "parameters = [storage.store_parameters(p) for p in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836afe62-0b01-4a52-a57c-fdf500426643",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"oneToN\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Act as a schema matcher for relational schemas. Your task is to create semantic matches\"\n",
    "                \" that specify how the elements of the source schema and the target schema semantically\"\n",
    "                \" correspond to one another. Two attributes semantically match if and only if there exists\"\n",
    "                \" an invertible function that maps all values of one attribute to the other. First, I will\"\n",
    "                \" input the name of an attribute from the source schema, a description of the attribute,\"\n",
    "                \" the name of the relation in belongs to and a description of this relation. After that, I\"\n",
    "                \" will input the same information of a single relation and all its attributes from the\"\n",
    "                \" target schema.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The attribute from the source schema is the following:\\n\"\n",
    "                \"Attribute name: '{{source_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{source_attribute.description}}'\\n\"\n",
    "                \"Relation name: '{{source_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{source_relation.description}}'\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The relation from the target schema is the following:\\n\"\n",
    "                \"Relation name: '{{target_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{target_relation.description}}'\\n\"\n",
    "                \"In the following, I will list all attributes of '{{target_relation.name}}'.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Attribute name: '{{target_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{target_attribute.description}}'\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Explain which of the target attributes semantically match to '{{source_attribute.name}}'\"\n",
    "                \" from '{{source_relation.name}}' of the source schema. Lets work this out step by step to\"\n",
    "                \" make sure we get it correct. After your explanation, give a final decision\"\n",
    "                \" JSON-formatted like this: `{ \\\"yes\\\": [], \\\"no\\\": [] }`. Under each of the following\"\n",
    "                \" keys, list all target attributes of '{{target_relation.name}}' that apply: yes - if\"\n",
    "                \" there is an invertible function that maps all values of the source attribute to the\"\n",
    "                \" values of the target attribute; no - if there is no such function. Do not mention an\"\n",
    "                \" attribute if there is not enough information to decide.\"\n",
    "            )\n",
    "        }\n",
    "    ],\n",
    "    \"nToOne\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Act as a schema matcher for relational schemas. Your task is to create semantic matches\"\n",
    "                \" that specify how the elements of the source schema and the target schema semantically\"\n",
    "                \" correspond to one another. Two attributes semantically match if and only if there exists\"\n",
    "                \" an invertible function that maps all values of one attribute to the other. First, I will\"\n",
    "                \" input the name of a single relation from the source schema, the description of the\"\n",
    "                \" relation and the name and description of all its attributes. After that, I will input\"\n",
    "                \" the same information of a single relation and a single attribute from the target schema.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The relation from the source schema is the following:\\n\"\n",
    "                \"Relation name: '{{source_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{source_relation.description}}'\\n\"\n",
    "                \"In the following, I will list all attributes of '{{source_relation.name}}'.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Attribute name: '{{source_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{source_attribute.description}}'\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The attribute from the target schema is the following:\\n\"\n",
    "                \"Relation name: '{{target_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{target_relation.description}}'\\n\"\n",
    "                \"Attribute name: '{{target_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{target_attribute.description}}'\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Explain which of the source attributes semantically match to '{{target_attribute.name}}'\"\n",
    "                \" from '{{target_relation.name}}' of the target schema. Lets work this out step by step to\"\n",
    "                \" make sure we get it correct. After your explanation, give a final decision\"\n",
    "                \" JSON-formatted like this: `{ \\\"yes\\\": [], \\\"no\\\": [] }`. Under each of the following\"\n",
    "                \" keys, list all target attributes of '{{source_relation.name}}' that apply: yes - if\"\n",
    "                \" there is an invertible function that maps all values of the source attribute to the\"\n",
    "                \" values of the target attribute; no - if there is no such function. Do not mention an\"\n",
    "                \" attribute if there is not enough information to decide.\"\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    \"nToN\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Act as a schema matcher for relational schemas. Your task is to create semantic matches\"\n",
    "                \" that specify how the elements of the source schema and the target schema semantically\"\n",
    "                \" correspond to one another. Two attributes semantically match if and only if there exists\"\n",
    "                \" an invertible function that maps all values of one attribute to the other. First, I will\"\n",
    "                \" input the name of a single relation from the source schema, the description of the\"\n",
    "                \" relation and the name and description of all its attributes. After that, I will input\"\n",
    "                \" the same information of one relation and all its attribute from the target schema.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The relation from the source schema is the following:\\n\"\n",
    "                \"Relation name: '{{source_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{source_relation.description}}'\\n\"\n",
    "                \"In the following, I will list all attributes of '{{source_relation.name}}'.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Attribute name: '{{source_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{source_attribute.description}}'\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"The relation from the target schema is the following:\\n\"\n",
    "                \"Relation name: '{{target_relation.name}}'\\n\"\n",
    "                \"Relation description: '{{target_relation.description}}'\\n\"\n",
    "                \"In the following, I will list all attributes of '{{target_relation.name}}'.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Attribute name: '{{target_attribute.name}}'\\n\"\n",
    "                \"Attribute description: '{{target_attribute.description}}'\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Explain which pairs of attributes from the source and target schema semantically match.\"\n",
    "                \" Lets work this out step by step to make sure we get it correct. After your explanation,\"\n",
    "                \" give a final decision JSON-formatted like this: `{ \\\"yes\\\": [], \\\"no\\\": [] }`. List all\"\n",
    "                \" attribute pairs written as `<source attribute>,<target attribute>` under one the\"\n",
    "                \" following keys where they apply: yes - if there is an invertible function that maps all\"\n",
    "                \" values of the source attribute to the values of the target attribute; no - if there is\"\n",
    "                \" no such function. Do not mention an attribute pair if there is not enough information to\"\n",
    "                \" decide.\"\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "os.makedirs(name = os.getenv(\"TEMPLATE_DIR\"), exist_ok=True)\n",
    "for tpl_name in all_templates:\n",
    "    with open(os.path.join(os.getenv(\"TEMPLATE_DIR\"), f\"{tpl_name}.json\"), \"w\") as jsn:\n",
    "        json.dump(templates[tpl_name.split(\"_\")[-1]], jsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a68db-176e-4fdf-9a49-3986cfaca8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing parameter: nostore/parameters/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3697, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/nb/k0s6d_3s7z53clvb94_wfncm0000gn/T/ipykernel_67830/3888397329.py\", line 16, in <module>\n",
      "  |     answers = await process_prompt_list(parameter, prompts[parameter.meta[\"path\"]])\n",
      "  |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 90, in process_prompt_list\n",
      "  |     async with asyncio.TaskGroup() as tg:\n",
      "  |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/taskgroups.py\", line 145, in __aexit__\n",
      "  |     raise me from None\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (27 sub-exceptions)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 2 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 3 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 4 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 5 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 6 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 7 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 8 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 9 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 10 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 11 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 12 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 13 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 14 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- 15 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 60, in process_and_store_prompt\n",
      "    |     for attempt in tenacity.Retrying(\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 445, in __iter__\n",
      "    |     do = self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n",
      "    |     result = action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 66, in process_and_store_prompt\n",
      "    |     result = await ask_gpt(_completion_prompt)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    |     return await copy(fn, *args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/fm_matcher/utils/prompt_sending.py\", line 34, in ask_gpt\n",
      "    |     client = AsyncOpenAI()\n",
      "    |              ^^^^^^^^^^^^^\n",
      "    |   File \"/Users/adhistri/schema-matching-using-llm-benchmarks/lib/python3.12/site-packages/openai/_client.py\", line 488, in __init__\n",
      "    |     raise OpenAIError(\n",
      "    | openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "    +---------------- ... ----------------\n",
      "    | and 12 more exceptions\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = {\n",
    "    parameter.meta[\"path\"]: build_prompts(parameters=parameter, templates=all_templates, modes=all_modes)\n",
    "    for parameter in parameters\n",
    "}\n",
    "\n",
    "prompts = {\n",
    "    param_path: [storage.store_prompt(prompt) for prompt in prompt_list]\n",
    "    for param_path, prompt_list in prompts.items()\n",
    "}\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "results = {}\n",
    "for parameter in parameters:\n",
    "    print(f\"Processing parameter: {parameter.meta['path']}\")\n",
    "    answers = await process_prompt_list(parameter, prompts[parameter.meta[\"path\"]])\n",
    "    print(f\"Completed parameter: {parameter.meta['path']}\")\n",
    "    results[parameter.meta[\"path\"]] = storage.store_result(postprocess_answers(parameter, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a008a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de7e5147-b006-4e74-a5d9-cd61f2725405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/k0s6d_3s7z53clvb94_wfncm0000gn/T/ipykernel_977/2141895632.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result_df[\"benchmark\"] = result_df[\"benchmark\"].fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_scope</th>\n",
       "      <th>source</th>\n",
       "      <th>source_attribute</th>\n",
       "      <th>source_relation</th>\n",
       "      <th>target</th>\n",
       "      <th>target_attribute</th>\n",
       "      <th>target_relation</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_index</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69904</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69905</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69906</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69907</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69908</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69909 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_scope                       source source_attribute  \\\n",
       "0         n-to-1           mimic.patients.dod              Dod   \n",
       "1         n-to-1           mimic.patients.dod              Dod   \n",
       "2         n-to-1           mimic.patients.dod              Dod   \n",
       "3         n-to-1           mimic.patients.dod              Dod   \n",
       "4         n-to-1           mimic.patients.dod              Dod   \n",
       "...          ...                          ...              ...   \n",
       "69904     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69905     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69906     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69907     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69908     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "\n",
       "      source_relation                                       target  \\\n",
       "0            Patients              omop.person.person_source_value   \n",
       "1            Patients              omop.person.person_source_value   \n",
       "2            Patients              omop.person.person_source_value   \n",
       "3            Patients              omop.person.person_source_value   \n",
       "4            Patients              omop.person.person_source_value   \n",
       "...               ...                                          ...   \n",
       "69904       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69905       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69906       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69907       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69908       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "\n",
       "                target_attribute target_relation decision  decision_index  \\\n",
       "0            Person_source_value          Person       no               0   \n",
       "1            Person_source_value          Person       no               1   \n",
       "2            Person_source_value          Person       no               2   \n",
       "3            Person_source_value          Person       no               3   \n",
       "4            Person_source_value          Person       no               4   \n",
       "...                          ...             ...      ...             ...   \n",
       "69904  Preceding_visit_detail_id    Visit_detail  unknown              10   \n",
       "69905  Preceding_visit_detail_id    Visit_detail  unknown              11   \n",
       "69906  Preceding_visit_detail_id    Visit_detail  unknown              12   \n",
       "69907  Preceding_visit_detail_id    Visit_detail  unknown              13   \n",
       "69908  Preceding_visit_detail_id    Visit_detail  unknown              14   \n",
       "\n",
       "       benchmark  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "69904      False  \n",
       "69905      False  \n",
       "69906      False  \n",
       "69907      False  \n",
       "69908      False  \n",
       "\n",
       "[69909 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result_to_dataframe(result: Result) -> pd.DataFrame:\n",
    "    df_data = []\n",
    "    for attribute_pair, result_pair in result.pairs.items():\n",
    "        for vote in result_pair.votes:\n",
    "            left_scope = \"1\" if len(vote.answer.attributes.sources) == 1 else \"n\"\n",
    "            right_scope = \"1\" if len(vote.answer.attributes.targets) == 1 else \"n\"\n",
    "            task_scope = left_scope + \"-to-\" + right_scope\n",
    "            source = \"mimic.\" + result.parameters.source_relation.name + \".\" + attribute_pair.source.name\n",
    "            target = \"omop.\" + result.parameters.target_relation.name + \".\" + attribute_pair.target.name\n",
    "            df_data.append({\n",
    "                \"task_scope\": task_scope,\n",
    "                \"source\": source.lower(),\n",
    "                \"source_attribute\": attribute_pair.source.name,\n",
    "                \"source_relation\": result.parameters.source_relation.name,\n",
    "                \"target\": target.lower(),\n",
    "                \"target_attribute\": attribute_pair.target.name,\n",
    "                \"target_relation\": result.parameters.target_relation.name,\n",
    "                \"decision\": str(vote.vote),\n",
    "                \"decision_index\": vote.answer.index,\n",
    "            })\n",
    "    return pd.DataFrame(df_data)\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "for result in results.values():\n",
    "    result_df = pd.concat((result_df, result_to_dataframe(result)))\n",
    "\n",
    "result_df = result_df.merge(benchmark[[\"source\", \"target\", \"benchmark\"]], on=[\"source\", \"target\"], how=\"left\").copy()\n",
    "result_df[\"benchmark\"] = result_df[\"benchmark\"].fillna(False)\n",
    "result_df.to_csv(\"results/gpt4_results.csv\", index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d656d8e8-1d30-4f7e-90ba-e77bc7add305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_scope</th>\n",
       "      <th>source</th>\n",
       "      <th>source_attribute</th>\n",
       "      <th>source_relation</th>\n",
       "      <th>target</th>\n",
       "      <th>target_attribute</th>\n",
       "      <th>target_relation</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_index</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-to-1</td>\n",
       "      <td>mimic.patients.dod</td>\n",
       "      <td>Dod</td>\n",
       "      <td>Patients</td>\n",
       "      <td>omop.person.person_source_value</td>\n",
       "      <td>Person_source_value</td>\n",
       "      <td>Person</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69904</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69905</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69906</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69907</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69908</th>\n",
       "      <td>n-to-n</td>\n",
       "      <td>mimic.transfers.transfer_id</td>\n",
       "      <td>Transfer_id</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>omop.visit_detail.preceding_visit_detail_id</td>\n",
       "      <td>Preceding_visit_detail_id</td>\n",
       "      <td>Visit_detail</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69909 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_scope                       source source_attribute  \\\n",
       "0         n-to-1           mimic.patients.dod              Dod   \n",
       "1         n-to-1           mimic.patients.dod              Dod   \n",
       "2         n-to-1           mimic.patients.dod              Dod   \n",
       "3         n-to-1           mimic.patients.dod              Dod   \n",
       "4         n-to-1           mimic.patients.dod              Dod   \n",
       "...          ...                          ...              ...   \n",
       "69904     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69905     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69906     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69907     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "69908     n-to-n  mimic.transfers.transfer_id      Transfer_id   \n",
       "\n",
       "      source_relation                                       target  \\\n",
       "0            Patients              omop.person.person_source_value   \n",
       "1            Patients              omop.person.person_source_value   \n",
       "2            Patients              omop.person.person_source_value   \n",
       "3            Patients              omop.person.person_source_value   \n",
       "4            Patients              omop.person.person_source_value   \n",
       "...               ...                                          ...   \n",
       "69904       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69905       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69906       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69907       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "69908       Transfers  omop.visit_detail.preceding_visit_detail_id   \n",
       "\n",
       "                target_attribute target_relation decision  decision_index  \\\n",
       "0            Person_source_value          Person       no               0   \n",
       "1            Person_source_value          Person       no               1   \n",
       "2            Person_source_value          Person       no               2   \n",
       "3            Person_source_value          Person       no               3   \n",
       "4            Person_source_value          Person       no               4   \n",
       "...                          ...             ...      ...             ...   \n",
       "69904  Preceding_visit_detail_id    Visit_detail  unknown              10   \n",
       "69905  Preceding_visit_detail_id    Visit_detail  unknown              11   \n",
       "69906  Preceding_visit_detail_id    Visit_detail  unknown              12   \n",
       "69907  Preceding_visit_detail_id    Visit_detail  unknown              13   \n",
       "69908  Preceding_visit_detail_id    Visit_detail  unknown              14   \n",
       "\n",
       "       benchmark  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "69904      False  \n",
       "69905      False  \n",
       "69906      False  \n",
       "69907      False  \n",
       "69908      False  \n",
       "\n",
       "[69909 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"results/gpt4_results.csv\")\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schema-matching-using-llm-benchmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
